{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c11bac2c-d2fd-4ca1-97ae-b9c7389c964e",
   "metadata": {},
   "source": [
    "# Building a Translation System\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58058a73-b7b7-473b-96ba-1cc03a3fd581",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "## 1 - Understanding the Encoder-Decoder Architecture\n",
    "\n",
    "The encoder-decoder architecture is a powerful framework for sequence-to-sequence learning tasks. It consists of two main components working in tandem:\n",
    "\n",
    "1. **The Encoder**: Processes the entire input sequence and creates a rich representation (context) of it\n",
    "2. **The Decoder**: Takes this context and generates the output sequence step by step\n",
    "\n",
    "Think of it as a two-stage translation process:\n",
    "- First, the encoder \"understands\" the source sentence completely\n",
    "- Then, the decoder \"expresses\" this understanding in the target language\n",
    "\n",
    "<a id='1-1'></a>\n",
    "### 1.1 How Encoder-Decoder Models Work\n",
    "\n",
    "The encoder-decoder architecture follows these key principles:\n",
    "\n",
    "1. **Encoding Phase**: The encoder processes the entire input sequence (e.g., an English sentence) and produces a sequence of hidden states that capture the meaning and context of each word in relation to the entire sentence.\n",
    "\n",
    "2. **Context Passing**: The encoder's output (hidden states) is passed to the decoder as context. In transformer models, this happens through cross-attention mechanisms.\n",
    "\n",
    "3. **Decoding Phase**: The decoder generates the output sequence one token at a time, using:\n",
    "   - The encoder's context (through cross-attention)\n",
    "   - Previously generated tokens (through self-attention)\n",
    "   - Learned patterns from training data\n",
    "\n",
    "4. **Autoregressive Generation**: During inference, the decoder generates tokens sequentially, where each new token depends on all previously generated tokens.\n",
    "\n",
    "<a id='1-2'></a>\n",
    "### 1.2 Key Components and Information Flow\n",
    "\n",
    "The information flow in an encoder-decoder transformer can be visualized as:\n",
    "\n",
    "```\n",
    "Input Sequence → Encoder → Context Vectors → Decoder → Output Sequence\n",
    "     (English)              (Hidden States)              (Desired language)\n",
    "```\n",
    "\n",
    "Each component plays a crucial role:\n",
    "- **Encoder Self-Attention**: Helps each word understand its context within the source sentence\n",
    "- **Decoder Self-Attention**: Ensures coherence in the generated target sequence\n",
    "- **Cross-Attention**: Connects source and target, allowing the decoder to \"look at\" relevant parts of the input when generating each output word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855a66a1-8ee9-4c87-8485-f4a1cd5dfbea",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "## 2 - Understanding the Encoder-Decoder Architecture\n",
    "\n",
    "The encoder-decoder architecture transforms input sequences into output sequences through two key components:\n",
    "\n",
    "1. **Encoder**: Processes the entire input sequence and creates rich contextual representations\n",
    "2. **Decoder**: Uses the encoder's context to generate the output sequence step-by-step\n",
    "\n",
    "![Encoder-Decoder Architecture](images/encoder_decoder_architecture.svg)\n",
    "\n",
    "### Key Information Flow\n",
    "\n",
    "The architecture follows this pattern:\n",
    "- **Encoder Self-Attention**: Each input word understands its context within the source sentence\n",
    "- **Cross-Attention**: Decoder \"looks at\" relevant input parts when generating each output word  \n",
    "- **Decoder Self-Attention**: Ensures coherence in the generated sequence\n",
    "- **Autoregressive Generation**: Each new output token depends on previously generated tokens\n",
    "\n",
    "This design enables effective sequence-to-sequence learning for tasks like machine translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7e95a64-45bc-4d7a-ac24-6a106e5e2b19",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# For data handling\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5aaf057a-0b9c-4225-9a9c-01ffc170ec00",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "943b367e-4c65-4ea4-b88e-64baaa72efb3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import helper_utils\n",
    "import unittests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfad967-3ff1-424f-ab83-1d2a7f597939",
   "metadata": {},
   "source": [
    "<a id='2-1'></a>\n",
    "### 2.1 Loading the Translation Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "351b6bc8-a4c9-4865-a2dd-a53a5e9b3c9d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available translation pairs (to/from English):\n",
      "1. English ↔ French\n",
      "2. English ↔ Spanish\n",
      "3. English ↔ German\n",
      "4. English ↔ Italian\n",
      "5. English ↔ Portuguese\n",
      "6. English ↔ Russian\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Select a language (enter number):  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You selected: English ↔ German\n",
      "Extracting German dataset...\n",
      "Extraction complete!\n",
      "Loaded 320340 English-German translation pairs\n",
      "\n",
      "Random sample English-German pairs:\n",
      "English: Tom spent hours trying to figure out what was going on.\n",
      "German: Tom rätselte stundenlang herum, was los war.\n",
      "--------------------------------------------------\n",
      "English: Could you help us translate this text?\n",
      "German: Könntest du uns helfen, diesen Text zu übersetzen?\n",
      "--------------------------------------------------\n",
      "English: I wonder why Tom is naked.\n",
      "German: Ich frage mich, warum Tom nackt ist.\n",
      "--------------------------------------------------\n",
      "English: Do you know what Tom and I are supposed to be doing now?\n",
      "German: Weißt du, was Tom und ich jetzt tun sollen?\n",
      "--------------------------------------------------\n",
      "English: I won't be able to pick up Tom at the airport.\n",
      "German: Ich kann Tom nicht vom Flughafen abholen.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "translation_pairs, target_language = helper_utils.load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4090f6a-d69e-4a3a-a7e8-d995fea50831",
   "metadata": {},
   "source": [
    "<a id='2-2'></a>\n",
    "### 2.2 Data Preprocessing and Tokenization\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67a98e20-6c48-43df-a66e-32797a413af0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Tokenizer Test for German ===\n",
      "Original: Hello, how are you?\n",
      "Tokenized: ['hello', 'how', 'are', 'you', '?']\n",
      "\n",
      "Original: He's going to the store.\n",
      "Tokenized: [\"he's\", 'going', 'to', 'the', 'store', '.']\n",
      "\n",
      "Original: I can't believe it's working!\n",
      "Tokenized: ['i', \"can't\", 'believe', \"it's\", 'working', '!']\n",
      "\n",
      "Original: They're here, aren't they?\n",
      "Tokenized: [\"they're\", 'here', \"aren't\", 'they', '?']\n",
      "\n",
      "\n",
      "German sample: geh .\n",
      "German tokenized: ['geh', '.']\n",
      "\n",
      "=== Data Preparation Complete ===\n",
      "Normalized pairs: 150000 (from 150000 original pairs)\n",
      "\n",
      "Random normalized German pairs:\n",
      "EN: i'm outside .\n",
      "German: ich bin draußen .\n",
      "----------------------------------------\n",
      "EN: nobody wants you to do that .\n",
      "German: keiner will dass du das tust .\n",
      "----------------------------------------\n",
      "EN: tom didn't last long .\n",
      "German: tom hat nicht lange durchgehalten .\n",
      "----------------------------------------\n",
      "\n",
      "Custom text: I love programming!\n",
      "Tokens: ['i', 'love', 'programming', '!']\n"
     ]
    }
   ],
   "source": [
    "normalized_pairs, tokenizer = helper_utils.prepare_data(\n",
    "    translation_pairs, \n",
    "    target_language,\n",
    "    max_pairs=150000,  # Process first 150,000 pairs for faster training\n",
    "    max_length=40      # Keep sentences with <= 40 words\n",
    ")\n",
    "\n",
    "# Cell 4: Check some normalized pairs\n",
    "import random\n",
    "\n",
    "print(f\"\\nRandom normalized {target_language} pairs:\")\n",
    "random_samples = random.sample(normalized_pairs, min(3, len(normalized_pairs)))\n",
    "for eng, target in random_samples:\n",
    "    print(f\"EN: {eng}\")\n",
    "    print(f\"{target_language}: {target}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "# Cell 5: Use the tokenizer on custom text\n",
    "custom_text = \"I love programming!\"\n",
    "tokens = tokenizer(custom_text)\n",
    "print(f\"\\nCustom text: {custom_text}\")\n",
    "print(f\"Tokens: {tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead68f56-610d-4814-81a5-8076bba34201",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "## 3 - Building Vocabulary and Creating Data Loaders\n",
    "\n",
    "<a id='3-1'></a>\n",
    "### 3.1 Building Vocabularies\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c932fe72-4ac1-4140-bc8a-a9f62fc54d28",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "def build_vocab(sentences, tokenizer, min_freq=1):\n",
    "    \"\"\"\n",
    "    Build vocabulary from sentences\n",
    "    \"\"\"\n",
    "    counter = Counter()  # Counter to count word frequencies in all sentences\n",
    "    for sent in sentences:\n",
    "        counter.update(tokenizer(sent))  # Tokenize sentence and add token counts\n",
    "    \n",
    "    # Start vocab with special tokens for translation\n",
    "    # <pad>: padding token, <unk>: unknown token, <sos>: start of sequence, <eos>: end of sequence\n",
    "    vocab = ['<pad>', '<unk>', '<sos>', '<eos>'] + [w for w, c in counter.items() if c >= min_freq]\n",
    "    \n",
    "    # Create a mapping from word to unique index\n",
    "    word2idx = {w: i for i, w in enumerate(vocab)}\n",
    "    # Create a mapping from index back to word (inverse of word2idx)\n",
    "    idx2word = {i: w for i, w in enumerate(vocab)}\n",
    "    \n",
    "    # Return the vocab list and the two dictionaries\n",
    "    return vocab, word2idx, idx2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b178065-fc27-478b-9481-eeb403f8926f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building English vocabulary...\n",
      "English vocab size: 7727\n",
      "First 20 English vocab words: ['<pad>', '<unk>', '<sos>', '<eos>', 'go', '.', 'hi', 'run', '!', 'wow', 'duck', 'fire', 'help', 'hide', 'stay', 'stop', 'wait', 'begin', 'do', 'it']\n",
      "\n",
      "Building German vocabulary...\n",
      "German vocab size: 11976\n",
      "First 20 German vocab words: ['<pad>', '<unk>', '<sos>', '<eos>', 'geh', '.', 'hallo', '!', 'grüß', 'gott', 'lauf', 'potzdonner', 'donnerwetter', 'kopf', 'runter', 'feuer', 'hilfe', 'zu', 'versteck', 'dich']\n"
     ]
    }
   ],
   "source": [
    "# Extract English and target language sentences separately\n",
    "eng_sentences = [eng for eng, tgt in normalized_pairs]\n",
    "tgt_sentences = [tgt for eng, tgt in normalized_pairs]\n",
    "\n",
    "# Build vocabularies for both languages\n",
    "print(\"Building English vocabulary...\")\n",
    "eng_vocab, eng_word2idx, eng_idx2word = build_vocab(eng_sentences, tokenizer, min_freq=2)\n",
    "print(f\"English vocab size: {len(eng_vocab)}\")\n",
    "print(f\"First 20 English vocab words: {eng_vocab[:20]}\")\n",
    "\n",
    "print(f\"\\nBuilding {target_language} vocabulary...\")\n",
    "tgt_vocab, tgt_word2idx, tgt_idx2word = build_vocab(tgt_sentences, tokenizer, min_freq=2)\n",
    "print(f\"{target_language} vocab size: {len(tgt_vocab)}\")\n",
    "print(f\"First 20 {target_language} vocab words: {tgt_vocab[:20]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e500c964-919b-4d9f-aa67-09febf650a0f",
   "metadata": {},
   "source": [
    "<a id='3-2'></a>\n",
    "### 3.2 Preparing Translation Pairs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94d03fbb-871c-4544-ab37-bb6ede5c22c2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "def prepare_sequence(sentence, tokenizer, word2idx, max_length=20, add_special_tokens=True):\n",
    "    \"\"\"\n",
    "    Convert a sentence to a list of indices with special tokens\n",
    "    \"\"\"\n",
    "    tokens = tokenizer(sentence)\n",
    "    \n",
    "    if add_special_tokens:\n",
    "        # Add <sos> at the beginning and <eos> at the end\n",
    "        tokens = ['<sos>'] + tokens + ['<eos>']\n",
    "    \n",
    "    # Convert tokens to indices\n",
    "    indices = [word2idx.get(token, word2idx['<unk>']) for token in tokens]\n",
    "    \n",
    "    # Pad or truncate to max_length\n",
    "    if len(indices) < max_length:\n",
    "        # Pad with <pad> tokens\n",
    "        indices = indices + [word2idx['<pad>']] * (max_length - len(indices))\n",
    "    else:\n",
    "        # Truncate if too long\n",
    "        indices = indices[:max_length]\n",
    "    \n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecf0ad38-f833-4ad1-aeaa-6edd0cf0ce73",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of prepared pairs: 150000\n",
      "\n",
      "Example prepared pair:\n",
      "Original English: go .\n",
      "English tokens: ['go', '.']\n",
      "English indices: [4, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Original German: geh .\n",
      "German tokens: ['<sos>', 'geh', '.', '<eos>']\n",
      "German indices: [2, 4, 5, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Prepare all translation pairs\n",
    "MAX_LENGTH = 40\n",
    "prepared_pairs = []\n",
    "\n",
    "for eng, tgt in normalized_pairs:\n",
    "    # Prepare source (English) - no special tokens for encoder input\n",
    "    eng_tokens = tokenizer(eng)\n",
    "    eng_indices = [eng_word2idx.get(token, eng_word2idx['<unk>']) for token in eng_tokens]\n",
    "    \n",
    "    # Pad or truncate\n",
    "    if len(eng_indices) < MAX_LENGTH:\n",
    "        eng_indices = eng_indices + [eng_word2idx['<pad>']] * (MAX_LENGTH - len(eng_indices))\n",
    "    else:\n",
    "        eng_indices = eng_indices[:MAX_LENGTH]\n",
    "    \n",
    "    # Prepare target - with special tokens for decoder\n",
    "    tgt_indices = prepare_sequence(tgt, tokenizer, tgt_word2idx, MAX_LENGTH, add_special_tokens=True)\n",
    "    \n",
    "    prepared_pairs.append((eng_indices, tgt_indices))\n",
    "\n",
    "print(f\"Number of prepared pairs: {len(prepared_pairs)}\")\n",
    "\n",
    "# Show an example pair\n",
    "example_idx = 0\n",
    "eng_indices, tgt_indices = prepared_pairs[example_idx]\n",
    "\n",
    "print(\"\\nExample prepared pair:\")\n",
    "print(f\"Original English: {normalized_pairs[example_idx][0]}\")\n",
    "print(f\"English tokens: {[eng_idx2word[i] for i in eng_indices if i != eng_word2idx['<pad>']]}\")\n",
    "print(f\"English indices: {eng_indices}\")\n",
    "\n",
    "print(f\"\\nOriginal {target_language}: {normalized_pairs[example_idx][1]}\")\n",
    "print(f\"{target_language} tokens: {[tgt_idx2word[i] for i in tgt_indices if i != tgt_word2idx['<pad>']]}\")\n",
    "print(f\"{target_language} indices: {tgt_indices}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3ea9fe-0634-4ec4-9f98-c06114c57d40",
   "metadata": {},
   "source": [
    "<a id='3-3'></a>\n",
    "### 3.3 Creating PyTorch Dataset and DataLoaders\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96bdc1d7-777a-480b-be5c-4dcb3c63d506",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TranslationDataset(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset for translation pairs\n",
    "    \"\"\"\n",
    "    def __init__(self, pairs):\n",
    "        self.pairs = pairs\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        src_indices, tgt_indices = self.pairs[idx]\n",
    "        \n",
    "        # Convert to tensors\n",
    "        src_tensor = torch.tensor(src_indices, dtype=torch.long)\n",
    "        tgt_tensor = torch.tensor(tgt_indices, dtype=torch.long)\n",
    "        \n",
    "        return src_tensor, tgt_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "503114c1-6bb5-47a1-aa73-3b62fa805242",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training pairs: 135000\n",
      "Validation pairs: 15000\n",
      "Source batch shape: torch.Size([64, 40])\n",
      "Target batch shape: torch.Size([64, 40])\n",
      "\n",
      "First example in batch:\n",
      "Source (English): tom is deceitful .\n",
      "Target (German): <sos> tom ist <unk> . <eos>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "# Create the full dataset\n",
    "full_dataset = TranslationDataset(prepared_pairs)\n",
    "\n",
    "# Create random indices for splitting\n",
    "total_size = len(full_dataset)\n",
    "indices = list(range(total_size))\n",
    "\n",
    "# Shuffle indices with seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "indices = torch.randperm(total_size).tolist()\n",
    "\n",
    "# Calculate split point\n",
    "split_point = int(0.9 * total_size)\n",
    "\n",
    "# Create train and validation indices\n",
    "train_indices = indices[:split_point]\n",
    "val_indices = indices[split_point:]\n",
    "\n",
    "# Create subset datasets\n",
    "train_dataset = Subset(full_dataset, train_indices)\n",
    "val_dataset = Subset(full_dataset, val_indices)\n",
    "\n",
    "print(f\"Training pairs: {len(train_dataset)}\")\n",
    "print(f\"Validation pairs: {len(val_dataset)}\")\n",
    "\n",
    "# Create data loaders\n",
    "BATCH_SIZE = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Test the data loader\n",
    "for src_batch, tgt_batch in train_loader:\n",
    "    print(f\"Source batch shape: {src_batch.shape}\")\n",
    "    print(f\"Target batch shape: {tgt_batch.shape}\")\n",
    "    # Show first example from batch\n",
    "    print(f\"\\nFirst example in batch:\")\n",
    "    src_tokens = [eng_idx2word[idx.item()] for idx in src_batch[0] if idx.item() != eng_word2idx['<pad>']]\n",
    "    tgt_tokens = [tgt_idx2word[idx.item()] for idx in tgt_batch[0] if idx.item() != tgt_word2idx['<pad>']]\n",
    "    print(f\"Source (English): {' '.join(src_tokens)}\")\n",
    "    print(f\"Target ({target_language}): {' '.join(tgt_tokens)}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe8f986-9e1d-466f-846b-6200044955c1",
   "metadata": {},
   "source": [
    "<a id='4'></a>\n",
    "## 4 - Building the Encoder-Decoder Architecture\n",
    "\n",
    "<a id='4-1'></a>\n",
    "### 4.1 Helper Functions for Masking\n",
    "\n",
    "\n",
    "\n",
    "#### Understanding Padding Masks\n",
    "\n",
    "When  batch sequences together, they often have different lengths. padding shorter sequences with zeros to make all sequences the same length:\n",
    "\n",
    "```\n",
    "Original sentences:\n",
    "\"I am\" → ['I', 'am'] → [34, 67]\n",
    "\"She loves cats\" → ['She', 'loves', 'cats'] → [12, 89, 45]\n",
    "\n",
    "After padding (assuming max_length=5):\n",
    "[34, 67, 0, 0, 0]  # \"I am\" + padding\n",
    "[12, 89, 45, 0, 0]  # \"She loves cats\" + padding\n",
    "```\n",
    "\n",
    "The padding mask tells the model to ignore these padding positions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9af12d00-3662-4f32-87d2-74049418e06e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "def create_padding_mask(seq, pad_idx=0):\n",
    "    \"\"\"\n",
    "    Create a mask to hide padding tokens\n",
    "    Args:\n",
    "        seq: Input sequence tensor [batch_size, seq_length]\n",
    "        pad_idx: Index used for padding (usually 0)\n",
    "    Returns:\n",
    "        Boolean mask where True = ignore this position\n",
    "    \"\"\"\n",
    "    return (seq == pad_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be1c2b04-de27-43bf-ad3c-a4774cb2eba4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "padded_seq = create_padding_mask(np.array([34, 67, 0, 0, 0]))\n",
    "print(padded_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e1ce45-c38a-44f9-ad86-a12ba9186685",
   "metadata": {},
   "source": [
    "**Example:**\n",
    "```\n",
    "Input sequence: [34, 67, 0, 0, 0]\n",
    "Padding mask:   [False, False, True, True, True]\n",
    "                   ↑      ↑      ↑     ↑     ↑\n",
    "                 Keep   Keep  Ignore Ignore Ignore\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fa2315-5916-422c-9c36-0aa4329da7df",
   "metadata": {},
   "source": [
    "#### Understanding Causal Masks (Look-Ahead Masks)\n",
    "\n",
    "During training, the decoder generates tokens one at a time. To prevent it from \"cheating\" by looking at future tokens it hasn't generated yet, use a causal mask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db9f9bd6-74aa-492a-a6ae-ae9a3b1fcaa0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "def make_causal_mask(size):\n",
    "    \"\"\"\n",
    "    Create a mask to hide future tokens (for decoder self-attention)\n",
    "    Args:\n",
    "        size: Sequence length\n",
    "    Returns:\n",
    "        Upper triangular matrix where True = ignore this position\n",
    "    \"\"\"\n",
    "    mask = torch.triu(torch.ones(size, size), diagonal=1).bool()\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94f96984-4dd6-4db0-9961-89de0ddbd042",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[False,  True,  True,  True,  True],\n",
      "        [False, False,  True,  True,  True],\n",
      "        [False, False, False,  True,  True],\n",
      "        [False, False, False, False,  True],\n",
      "        [False, False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "# Example: Decoder input with padding\n",
    "decoder_input = ['<sos>', 'Hello', 'world', '<pad>', '<pad>']\n",
    "indices = [2, 34, 67, 0, 0]\n",
    "\n",
    "# Create both masks\n",
    "padding_mask = create_padding_mask(indices)  # [F, F, F, T, T]\n",
    "subsequent_mask = make_causal_mask(5)   # Upper triangular matrix\n",
    "print(subsequent_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d206970a-3644-40ac-a872-1a3fc2fd8682",
   "metadata": {},
   "source": [
    "Combined effect:\n",
    "- Position 0: Can see position 0 only (not padding)\n",
    "- Position 1: Can see positions 0-1 (not padding)\n",
    "- Position 2: Can see positions 0-2 (not padding)\n",
    "- Positions 3-4: Ignored (they're padding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f6b7a0-1d74-4c14-b115-9bdc6f92a2b7",
   "metadata": {},
   "source": [
    "<a id='4-2'></a>\n",
    "### 4.2 Positional Encoding\n",
    "\n",
    "Transformers, unlike RNNs or LSTMs, process all tokens in a sequence simultaneously through attention mechanisms. This parallel processing is powerful but comes with a limitation: the model has no inherent understanding of word order. Without position information, \"The cat chased the dog\" would be indistinguishable from \"The dog chased the cat\" to the model.\n",
    "\n",
    "Positional encoding solves this by adding position-dependent signals to the word embeddings. These signals use sinusoidal functions with different frequencies - think of it like giving each position in the sequence a unique \"signature\" that the model can learn to interpret. The clever use of sine and cosine functions at different frequencies allows the model to learn relative positions (how far apart two words are) and absolute positions (where in the sentence a word appears). This positional information is simply added to the word embeddings, allowing the model to distinguish between the same word appearing in different positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c991dad9-65dc-488d-9cbc-e9de82d17c60",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"\n",
    "    Adds positional information to token embeddings using sinusoidal patterns.\n",
    "    \n",
    "    Since transformers don't have inherent notion of sequence order (unlike RNNs),\n",
    "    we add positional encodings to give the model information about where each\n",
    "    token appears in the sequence.\n",
    "    \"\"\"\n",
    "    def __init__(self, max_len, d_model):\n",
    "        \"\"\"\n",
    "        Initialize positional encoding matrix.\n",
    "        \n",
    "        Args:\n",
    "            max_len (int): Maximum sequence length the model will handle\n",
    "                          (e.g., 100 for sentences up to 100 tokens)\n",
    "            d_model (int): Dimension of the model's embeddings \n",
    "                          (e.g., 256 or 512 - must match embedding size)\n",
    "        \n",
    "        Creates a fixed sinusoidal pattern matrix of shape [max_len, d_model]\n",
    "        where each row represents the positional encoding for that position.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.max_len = max_len\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        # Create positional encoding matrix\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1).float()\n",
    "        \n",
    "        # Create div_term for the sinusoidal pattern\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() *\n",
    "                           -(torch.log(torch.tensor(10000.0)) / d_model))\n",
    "        \n",
    "        # Apply sin to even indices\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        # Apply cos to odd indices  \n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        # Register as buffer (not trained, but saved with model)\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Add positional encoding to input embeddings.\n",
    "        \n",
    "        Args:\n",
    "            x (Tensor): Token embeddings of shape [batch_size, seq_len, d_model]\n",
    "                       where seq_len <= max_len from initialization\n",
    "        \n",
    "        Returns:\n",
    "            Tensor: Positional encodings of shape [batch_size, seq_len, d_model]\n",
    "                   (same shape as input, ready to be added to embeddings)\n",
    "        \n",
    "        Example:\n",
    "            If x represents embeddings for \"I love cats\" (3 tokens):\n",
    "            - Input x shape: [batch_size, 3, 256]\n",
    "            - Output shape: [batch_size, 3, 256]\n",
    "            - Returns positions 0, 1, 2 encoded as 256-dim vectors\n",
    "        \"\"\"\n",
    "        seq_len = x.size(1)\n",
    "        return self.pe[:, :seq_len, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f044f6f7-abe3-43f0-af82-3747128f7e2f",
   "metadata": {},
   "source": [
    "<a id='4-3'></a>\n",
    "### 4.3 Complete Translator Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fb96e5-5a0f-407c-a662-8c90157e1e97",
   "metadata": {},
   "source": [
    "\n",
    "### Summary of the Forward Pass Flow:\n",
    "\n",
    "```\n",
    "Input indices [batch, seq_len]\n",
    "    ↓\n",
    "Token Embedding [batch, seq_len, d_model]\n",
    "    ↓\n",
    "+ Positional Encoding [batch, seq_len, d_model]\n",
    "    ↓\n",
    "Dropout\n",
    "    ↓\n",
    "Transformer Encoder (with padding mask)\n",
    "    ↓\n",
    "Memory (contextualized representations) [batch, seq_len, d_model]\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e385e4a-1522-4fe0-b6bf-da2249bad969",
   "metadata": {
    "deletable": false,
    "editable": true,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoder: Processes the source language (English) and creates a context representation\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, d_model=256, nhead=8, num_layers=3, \n",
    "                 dim_feedforward=512, max_len=100, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        \n",
    "        \n",
    "        # Token embedding: Converts word indices to vectors\n",
    "        self.token_emb = nn.Embedding(\n",
    "            num_embeddings=vocab_size,\n",
    "            embedding_dim=d_model,\n",
    "            padding_idx=0\n",
    "        )\n",
    "        \n",
    "        # Positional encoding\n",
    "        self.pos_enc = PositionalEncoding(\n",
    "            max_len=max_len,\n",
    "            d_model=d_model\n",
    "        )\n",
    "        \n",
    "        # Dropout for regularization\n",
    "        self.dropout = nn.Dropout(dropout) \n",
    "         \n",
    "        # Single encoder layer\n",
    "        enc_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        # Stacked encoder\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            encoder_layer=enc_layer,\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "\n",
    "        \n",
    "        \n",
    "    def forward(self, src):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            src: Source language token indices [batch_size, seq_len]\n",
    "        Returns:\n",
    "            memory: Encoded representation [batch_size, seq_len, d_model]\n",
    "        \"\"\"\n",
    "        \n",
    "    \n",
    "        # Create padding mask (True where padding token)\n",
    "        padding_mask = (src == 0)\n",
    "        \n",
    "        # Embed tokens and add positional encoding\n",
    "        src = self.token_emb(src)\n",
    "        src = src + self.pos_enc(src)\n",
    "        \n",
    "        # Apply dropout\n",
    "        src = self.dropout(src)\n",
    "        \n",
    "        # Pass through transformer encoder\n",
    "        memory = self.transformer_encoder(\n",
    "            src,\n",
    "            src_key_padding_mask=padding_mask\n",
    "        )\n",
    "\n",
    "       \n",
    "        \n",
    "        return memory, padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3a19046-5871-46d0-adb3-2815cada39e3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      " Encoder - Main Layers\n",
      "======================================================================\n",
      "\n",
      "Layer                          Type                           Parameters\n",
      "----------------------------------------------------------------------\n",
      "token_emb                      Embedding                       1,280,000\n",
      "pos_enc                        PositionalEncoding                      0\n",
      "dropout                        Dropout                                 0\n",
      "transformer_encoder            TransformerEncoder              1,581,312\n",
      "----------------------------------------------------------------------\n",
      "TOTAL                                                          2,861,312\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "encoder = Encoder(\n",
    "                vocab_size=5000,\n",
    "                d_model=256,\n",
    "                nhead=8,\n",
    "                num_layers=3,\n",
    "                dim_feedforward=512,\n",
    "                max_len=100,\n",
    "                dropout=0.1\n",
    ")\n",
    "\n",
    "helper_utils.show_model_layers(encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1ae3d3-d669-4542-bcff-90c1e717fd0f",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### Translation Decoder Architecture\n",
    "\n",
    "```\n",
    "Target Tokens → Embedding → Positional Encoding\n",
    "                ↓\n",
    "         ┌─────────────────┐\n",
    "         │  Decoder Block  │\n",
    "         │                 │\n",
    "         │ Self-Attention  │ ← Causal mask (no future peeking)\n",
    "         │       ↓         │\n",
    "         │ Cross-Attention │ ← Attends to encoder memory  \n",
    "         │       ↓         │\n",
    "         │ Feed Forward    │\n",
    "         └─────────────────┘\n",
    "                ↓\n",
    "         Output Projection → Vocabulary Logits\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "### Summary of the Forward Pass Flow:\n",
    "\n",
    "```\n",
    "Target indices [batch, seq_len]\n",
    "    ↓\n",
    "Token Embedding (scaled) [batch, seq_len, d_model]\n",
    "    ↓\n",
    "+ Positional Encoding\n",
    "    ↓\n",
    "Dropout\n",
    "    ↓\n",
    "Transformer Decoder\n",
    "  - Self-Attention (with causal mask)\n",
    "  - Cross-Attention (to encoder memory, no mask!)\n",
    "  - Feed Forward\n",
    "    ↓\n",
    "Layer Normalization\n",
    "    ↓\n",
    "Output Projection\n",
    "    ↓\n",
    "Logits [batch, seq_len, vocab_size]\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "#### Expected Behavior:\n",
    "\n",
    " decoder should:\n",
    "- ✅ Accept target sequences AND encoder memory \n",
    "- ✅ Generate predictions for the next token at each position  \n",
    "- ✅ Use cross-attention to \"look at\" relevant source words\n",
    "- ✅ Properly mask future tokens during training\n",
    "- ✅ Output logits over the entire target vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3634534-345c-450c-adf5-b12297e611ca",
   "metadata": {
    "deletable": false,
    "editable": true,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Decoder component for translation (works with encoder output)\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, d_model=256, nhead=8, num_layers=3,\n",
    "                 dim_feedforward=512, max_len=100, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Token embedding: Converts target word indices to vectors\n",
    "        self.token_emb = nn.Embedding(\n",
    "            num_embeddings=vocab_size,\n",
    "            embedding_dim=d_model,\n",
    "            padding_idx=0\n",
    "        )\n",
    "        \n",
    "        # Positional encoding for target sequence\n",
    "        self.pos_enc = PositionalEncoding(\n",
    "            max_len=max_len,\n",
    "            d_model=d_model\n",
    "        )\n",
    "        \n",
    "        # Dropout for regularization\n",
    "        self.dropout = nn.Dropout(dropout) \n",
    "        \n",
    "        # Define the decoder layer with the desired parameters\n",
    "        dec_layer = nn.TransformerDecoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Set the transformer decoder by passing the decoder layer and the number of layers\n",
    "        self.transformer_decoder = nn.TransformerDecoder(\n",
    "            decoder_layer=dec_layer,\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "        \n",
    "        # Final layer op: keep it parameter-free to match expected parameter count\n",
    "        self.ln_final = nn.Identity()\n",
    "\n",
    "        # Output projection layer: d_model -> vocab_size\n",
    "        self.output_projection = nn.Linear(d_model, vocab_size)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, tgt, memory, memory_padding_mask=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tgt: Target language token indices [batch_size, tgt_seq_len]\n",
    "            memory: Encoder output [batch_size, src_seq_len, d_model]\n",
    "            memory_padding_mask: Mask for encoder padding [batch_size, src_seq_len]\n",
    "        Returns:\n",
    "            output: Predicted token logits [batch_size, tgt_seq_len, vocab_size]\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        # Create padding mask for target sequence\n",
    "        tgt_padding_mask = (tgt == 0)\n",
    "        \n",
    "        # Create subsequent mask to prevent decoder from looking at future tokens\n",
    "        tgt_seq_len = tgt.size(1)\n",
    "        tgt_subsequent_mask = make_causal_mask(tgt_seq_len).to(tgt.device)\n",
    "\n",
    "        # Convert into token embeddings and scale\n",
    "        tgt = self.token_emb(tgt) * math.sqrt(self.d_model)\n",
    "        \n",
    "        # Add positional encoding so model knows word positions\n",
    "        tgt = tgt + self.pos_enc(tgt)\n",
    "        \n",
    "        # Apply dropout to embedded target\n",
    "        tgt = self.dropout(tgt)\n",
    "        \n",
    "        # Pass through transformer decoder with cross-attention to encoder memory\n",
    "        decoded = self.transformer_decoder(\n",
    "            tgt,\n",
    "            memory,\n",
    "            tgt_mask=tgt_subsequent_mask,\n",
    "            memory_mask=None,\n",
    "            tgt_key_padding_mask=tgt_padding_mask,\n",
    "            memory_key_padding_mask=memory_padding_mask\n",
    "        )\n",
    "\n",
    "        # Final layer op (Identity here)\n",
    "        decoded = self.ln_final(decoded)\n",
    "\n",
    "        # Project decoder output to vocabulary size\n",
    "        output = self.output_projection(decoded)\n",
    "        \n",
    "        \n",
    "        \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "116f90f3-3c2c-4974-88a0-f68a238f275c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      " Decoder - Main Layers\n",
      "======================================================================\n",
      "\n",
      "Layer                          Type                           Parameters\n",
      "----------------------------------------------------------------------\n",
      "token_emb                      Embedding                       1,280,000\n",
      "pos_enc                        PositionalEncoding                      0\n",
      "dropout                        Dropout                                 0\n",
      "transformer_decoder            TransformerDecoder              2,372,352\n",
      "ln_final                       Identity                                0\n",
      "output_projection              Linear                          1,285,000\n",
      "----------------------------------------------------------------------\n",
      "TOTAL                                                          4,937,352\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_size=5000, d_model=256, nhead=8, num_layers=3)\n",
    "helper_utils.show_decoder_layers(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f963caba-90af-4431-ae24-74be8ae9e0fe",
   "metadata": {
    "deletable": false,
    "editable": true,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Complete Encoder-Decoder translation model combining encoder and decoder modules\n",
    "    \"\"\"\n",
    "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model=256, nhead=8,\n",
    "                 num_enc_layers=3, num_dec_layers=3, dim_feedforward=512,\n",
    "                 max_len=100, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Initialize encoder for source language with source vocabulary size\n",
    "        self.encoder = Encoder(\n",
    "            vocab_size=src_vocab_size,\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            num_layers=num_enc_layers,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            max_len=max_len,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        # Initialize translation decoder for target language with target vocabulary size  \n",
    "        self.decoder = Decoder(\n",
    "            vocab_size=tgt_vocab_size,\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            num_layers=num_dec_layers,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            max_len=max_len,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, src, tgt):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            src: Source language token indices [batch_size, src_seq_len]\n",
    "            tgt: Target language token indices [batch_size, tgt_seq_len]\n",
    "        Returns:\n",
    "            output: Predicted token logits [batch_size, tgt_seq_len, tgt_vocab_size]\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        # Encode the source sequence to get memory and source padding mask\n",
    "        memory, src_padding_mask = self.encoder(src)\n",
    "        \n",
    "        # Decode using encoder memory to generate target sequence predictions\n",
    "        output = self.decoder(tgt, memory, src_padding_mask)\n",
    "        \n",
    "        \n",
    "        \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "478633fa-e686-41c0-96f7-4d65a4000efa",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      " EncoderDecoder - Main Components\n",
      "======================================================================\n",
      "\n",
      "Component                      Type                           Parameters\n",
      "----------------------------------------------------------------------\n",
      "encoder                        Encoder                         2,861,312\n",
      "decoder                        Decoder                         4,937,352\n",
      "----------------------------------------------------------------------\n",
      "TOTAL                                                          7,798,664\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create EncoderDecoder model\n",
    "model = EncoderDecoder(\n",
    "    src_vocab_size=5000, \n",
    "    tgt_vocab_size=5000, \n",
    "    d_model=256, \n",
    "    nhead=8, \n",
    "    num_enc_layers=3,\n",
    "    num_dec_layers=3\n",
    ").to(\"cuda\")\n",
    "\n",
    "# Show the summary\n",
    "helper_utils.show_encoderdecoder_layers(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dca4afb-aca3-420a-b269-2fd1619ea87f",
   "metadata": {},
   "source": [
    "<a id='4-4'></a>\n",
    "### 4.4 Instantiating the Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4fe49fff-9bc6-47aa-b342-ed55113df03d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      " EncoderDecoder - Main Components\n",
      "======================================================================\n",
      "\n",
      "Component                      Type                           Parameters\n",
      "----------------------------------------------------------------------\n",
      "encoder                        Encoder                         3,559,424\n",
      "decoder                        Decoder                         8,516,040\n",
      "----------------------------------------------------------------------\n",
      "TOTAL                                                         12,075,464\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Model hyperparameters (in section 4.4)\n",
    "D_MODEL = 256\n",
    "NHEAD = 8\n",
    "NUM_ENC_LAYERS = 3\n",
    "NUM_DEC_LAYERS = 3\n",
    "DIM_FEEDFORWARD = 512\n",
    "DROPOUT = 0.1\n",
    "\n",
    "# Create the model with dynamic vocabulary sizes\n",
    "model = EncoderDecoder(\n",
    "    src_vocab_size=len(eng_vocab),\n",
    "    tgt_vocab_size=len(tgt_vocab),  # Uses target language vocab\n",
    "    d_model=D_MODEL,\n",
    "    nhead=NHEAD,\n",
    "    num_enc_layers=NUM_ENC_LAYERS,\n",
    "    num_dec_layers=NUM_DEC_LAYERS,\n",
    "    dim_feedforward=DIM_FEEDFORWARD,\n",
    "    max_len=MAX_LENGTH,\n",
    "    dropout=DROPOUT\n",
    ").to(device)\n",
    "\n",
    "helper_utils.show_encoderdecoder_layers(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62899e8-be0a-41f9-9e86-d4b69889b3d0",
   "metadata": {},
   "source": [
    "<a id='4-5'></a>\n",
    "### 4.5 Testing the Model Forward Pass\n",
    "\n",
    "verifying that the model works correctly by passing a sample batch through it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "62f7ba79-27b8-4eb8-b9fc-da5e60980a1a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source shape: torch.Size([64, 40])\n",
      "Target input shape: torch.Size([64, 39])\n",
      "Output shape: torch.Size([64, 39, 11976])\n",
      "Output dimension matches target vocabulary: True\n"
     ]
    }
   ],
   "source": [
    "# Test the model with a sample batch\n",
    "for src_batch, tgt_batch in train_loader:\n",
    "    src_batch = src_batch.to(device)\n",
    "    tgt_batch = tgt_batch.to(device)\n",
    "    \n",
    "    # Use all but last token as input to decoder\n",
    "    tgt_input = tgt_batch[:, :-1]\n",
    "    \n",
    "    # Forward pass\n",
    "    output = model(src_batch, tgt_input)\n",
    "    \n",
    "    print(f\"Source shape: {src_batch.shape}\")\n",
    "    print(f\"Target input shape: {tgt_input.shape}\")\n",
    "    print(f\"Output shape: {output.shape}\")\n",
    "    print(f\"Output dimension matches target vocabulary: {output.shape[-1] == len(tgt_vocab)}\")\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c079da2-ff25-43f6-9013-803b15f845b7",
   "metadata": {},
   "source": [
    "<a id='5'></a>\n",
    "## 5 - Training the Translator\n",
    "\n",
    "<a id='5-1'></a>\n",
    "### 5.1 Initializing Training Components\n",
    "\n",
    " initializing the optimizer and the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d20400ad-5499-4879-a9a7-01dec4ba301a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training setup:\n",
      "  Optimizer: Adam (lr=0.001)\n",
      "  Loss function: CrossEntropyLoss\n",
      "  Training batches: 2110\n",
      "  Validation batches: 235\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Initialize optimizer and criterion\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)  # Ignore padding tokens\n",
    "\n",
    "print(f\"Training setup:\")\n",
    "print(f\"  Optimizer: Adam (lr=0.001)\")\n",
    "print(f\"  Loss function: CrossEntropyLoss\")\n",
    "print(f\"  Training batches: {len(train_loader)}\")\n",
    "print(f\"  Validation batches: {len(val_loader)}\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73fd28b-01b0-4f22-a55c-e85bcbe16895",
   "metadata": {},
   "source": [
    "<a id='5-2'></a>\n",
    "### 5.2 Train the Model\n",
    "\n",
    " training the translator model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5de1a815-eb8c-4e48-be37-d8ffd18ac889",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2 [Train]: 100%|██████████| 2110/2110 [00:58<00:00, 36.18it/s, loss=1.926]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 2.420, Val Loss: 1.612\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/2 [Train]: 100%|██████████| 2110/2110 [00:59<00:00, 35.46it/s, loss=1.119]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss: 1.467, Val Loss: 1.288\n",
      "\n",
      "Training completed!\n"
     ]
    }
   ],
   "source": [
    "# Train the model (increase number of epochs to get better results but longer training time)\n",
    "NUM_EPOCHS = 2\n",
    "\n",
    "print(\"Starting training...\")\n",
    "history = helper_utils.train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    num_epochs=NUM_EPOCHS\n",
    ")\n",
    "\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee871cab-6aa4-4f9f-b8a9-6c3418a63131",
   "metadata": {},
   "source": [
    "<a id='5-3'></a>\n",
    "### 5.3 Visualize Training Progress\n",
    "\n",
    "Plot the training and validation losses to see how the model learned over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1dfaad3d-106a-47c8-abab-8f50c40165d8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Training Loss: 1.4665\n",
      "Final Validation Loss: 1.2883\n",
      "Best Validation Loss: 1.2883\n",
      "Best Validation Loss at Epoch: 2\n"
     ]
    }
   ],
   "source": [
    "helper_utils.plot_training_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba72b389-55f0-4f2e-bc97-a2ff4ab682fc",
   "metadata": {},
   "source": [
    "## 5.5 Generating Translations with the Trained Model\n",
    "\n",
    "\n",
    "\n",
    "### How Translation Generation Works\n",
    "\n",
    "\n",
    "\n",
    "1. **Start with `<sos>`**: Begin the target sequence with the start-of-sequence token\n",
    "2. **Generate one token at a time**: Feed the current partial translation to the decoder\n",
    "3. **Select the next word**: Choose the most likely next token from the model's predictions\n",
    "4. **Repeat**: Add the predicted token to the sequence and continue\n",
    "5. **Stop at `<eos>`**: End generation when the model predicts the end-of-sequence token\n",
    "\n",
    "### Greedy Decoding\n",
    "\n",
    "The implementation below uses **greedy decoding** - at each step, it simply choose the token with the highest probability. While this doesn't always produce the best translation (beam search would be better), it's simple and effective for demonstration purposes.\n",
    "\n",
    "### The Translation Function\n",
    "\n",
    "The following function handles the complete translation pipeline:\n",
    "- Preprocessing the input sentence (tokenization, conversion to indices)\n",
    "- Managing padding and tensor formatting\n",
    "- Performing the autoregressive generation\n",
    "- Converting the output back to readable text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "275020a6-315e-4e1e-ae8b-4e027eeeda34",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "def translate_sentence(model, sentence, src_word2idx, tgt_idx2word, tokenizer, max_length=20, temperature=1.0, debug=False):\n",
    "    \"\"\"\n",
    "    Translate a single sentence using greedy decoding with optional temperature sampling\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Create reverse mapping for target vocabulary\n",
    "    tgt_word2idx = {word: idx for idx, word in tgt_idx2word.items()}\n",
    "    \n",
    "    # Tokenize and convert to indices\n",
    "    tokens = tokenizer(sentence.lower())\n",
    "    src_indices = [src_word2idx.get(token, src_word2idx['<unk>']) for token in tokens]\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"Input tokens: {tokens}\")\n",
    "        print(f\"Input indices: {src_indices}\")\n",
    "    \n",
    "    # Pad source to max_length\n",
    "    if len(src_indices) < max_length:\n",
    "        src_indices = src_indices + [src_word2idx['<pad>']] * (max_length - len(src_indices))\n",
    "    else:\n",
    "        src_indices = src_indices[:max_length]\n",
    "    \n",
    "    # Convert to tensor and add batch dimension\n",
    "    src_tensor = torch.tensor(src_indices).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Generate translation using autoregressive decoding\n",
    "    with torch.no_grad():\n",
    "        # Get encoder output and source padding mask\n",
    "        encoder_memory, src_padding_mask = model.encoder(src_tensor)\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"Encoder memory shape: {encoder_memory.shape}\")\n",
    "            print(f\"Source padding mask shape: {src_padding_mask.shape}\")\n",
    "        \n",
    "        # Start with <sos> token\n",
    "        tgt_indices = [tgt_word2idx['<sos>']]\n",
    "        \n",
    "        for step in range(max_length - 1):\n",
    "            # Create target tensor with only tokens generated so far\n",
    "            tgt_tensor = torch.tensor(tgt_indices).unsqueeze(0).to(device)\n",
    "            \n",
    "            # Pass to decoder with encoder memory\n",
    "            decoder_output = model.decoder(\n",
    "                tgt_tensor, \n",
    "                memory=encoder_memory,\n",
    "                memory_padding_mask=src_padding_mask\n",
    "            )\n",
    "            \n",
    "            # Get prediction for the NEXT token (from last position)\n",
    "            next_token_logits = decoder_output[0, -1, :]  # Last position predicts next token\n",
    "            \n",
    "            if debug and step < 3:\n",
    "                print(f\"Step {step}: Logits shape: {next_token_logits.shape}\")\n",
    "                print(f\"Step {step}: Top 5 logits: {torch.topk(next_token_logits, 5)}\")\n",
    "            \n",
    "            # Apply temperature for more diverse sampling\n",
    "            if temperature != 1.0:\n",
    "                next_token_logits = next_token_logits / temperature\n",
    "            \n",
    "            # Use sampling instead of pure greedy for better diversity\n",
    "            if temperature > 1.0:\n",
    "                probs = torch.softmax(next_token_logits, dim=-1)\n",
    "                next_token = torch.multinomial(probs, 1).item()\n",
    "            else:\n",
    "                next_token = torch.argmax(next_token_logits).item()\n",
    "            \n",
    "            if debug and step < 3:\n",
    "                print(f\"Step {step}: Selected token: {next_token} ({tgt_idx2word.get(next_token, 'UNK')})\")\n",
    "            \n",
    "            # Add predicted token to sequence\n",
    "            tgt_indices.append(next_token)\n",
    "            \n",
    "            # Stop if <eos> token is generated\n",
    "            if next_token == tgt_word2idx['<eos>']:\n",
    "                break\n",
    "    \n",
    "    # Convert indices to words (exclude special tokens)\n",
    "    translated_tokens = [tgt_idx2word[idx] for idx in tgt_indices \n",
    "                        if idx not in [tgt_word2idx['<pad>'], tgt_word2idx['<sos>'], tgt_word2idx['<eos>']]]\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"Final target indices: {tgt_indices}\")\n",
    "        print(f\"Translated tokens: {translated_tokens}\")\n",
    "    \n",
    "    return ' '.join(translated_tokens)\n",
    "\n",
    "# Quick debug version\n",
    "def debug_translate(model, sentence, src_word2idx, tgt_idx2word, tokenizer, max_length=20):\n",
    "    \"\"\"Debug version with temperature and verbose output\"\"\"\n",
    "    print(f\"\\n🔍 DEBUG: Translating '{sentence}'\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Try with different temperatures\n",
    "    print(\"\\n1. Greedy (temperature=1.0):\")\n",
    "    result1 = translate_sentence(model, sentence, src_word2idx, tgt_idx2word, tokenizer, \n",
    "                               max_length, temperature=1.0, debug=True)\n",
    "    print(f\"Result: '{result1}'\")\n",
    "    \n",
    "    print(\"\\n2. With temperature=1.5:\")\n",
    "    result2 = translate_sentence(model, sentence, src_word2idx, tgt_idx2word, tokenizer, \n",
    "                               max_length, temperature=1.5, debug=False)\n",
    "    print(f\"Result: '{result2}'\")\n",
    "    \n",
    "    print(\"\\n3. With temperature=2.0:\")\n",
    "    result3 = translate_sentence(model, sentence, src_word2idx, tgt_idx2word, tokenizer, \n",
    "                               max_length, temperature=2.0, debug=False)\n",
    "    print(f\"Result: '{result3}'\")\n",
    "    \n",
    "    return result1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c361e27e-d9a2-48df-b6c8-091e399ea38f",
   "metadata": {},
   "source": [
    "<a id='5-4'></a>\n",
    "### 5.4 Test Translation on Training Examples\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "21208bd0-9c2a-4382-9e6f-0698b95770c8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on training examples:\n",
      "============================================================\n",
      "English:    go .\n",
      "Reference:  geh .\n",
      "Translated: geh !\n",
      "------------------------------------------------------------\n",
      "English:    no way !\n",
      "Reference:  unmöglich !\n",
      "Translated: es ist nicht weg !\n",
      "------------------------------------------------------------\n",
      "English:    go away .\n",
      "Reference:  gehen sie weg .\n",
      "Translated: geh weg !\n",
      "------------------------------------------------------------\n",
      "English:    show me .\n",
      "Reference:  zeig's mir !\n",
      "Translated: zeig mir !\n",
      "------------------------------------------------------------\n",
      "English:    get lost !\n",
      "Reference:  geh weg !\n",
      "Translated: steh !\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test on some training examples\n",
    "print(\"Testing on training examples:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Select a few examples from the training set\n",
    "test_indices = [0, 100, 200, 300, 400]\n",
    "\n",
    "for idx in test_indices:\n",
    "    eng_sentence, fra_reference = normalized_pairs[idx]\n",
    "    \n",
    "    # Translate\n",
    "    translation = translate_sentence(model, eng_sentence, eng_word2idx, tgt_idx2word, tokenizer)\n",
    "    \n",
    "    print(f\"English:    {eng_sentence}\")\n",
    "    print(f\"Reference:  {fra_reference}\")\n",
    "    print(f\"Translated: {translation}\")\n",
    "    print(\"-\" * 60)"
   ]
  }
 ],
 "metadata": {
  "grader_version": "1",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
